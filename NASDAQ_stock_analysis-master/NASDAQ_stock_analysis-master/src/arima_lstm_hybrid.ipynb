{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arima_lstm_hybrid.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EGXtpmbk3le",
        "outputId": "a10e51cc-ae66-43d8-cee8-49d3fd5100d3"
      },
      "source": [
        "!pip install pmdarima==1.2.1\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n",
        "!dpkg -i libta.deb ta.deb\n",
        "!pip install TA-Lib==0.4.17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pmdarima==1.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/1d/1cf4dd83f3c129774343a642d4d42f9ad727d0d02f757893ea9c67514d78/pmdarima-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (913kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (1.18.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (0.10.2)\n",
            "Requirement already satisfied: Cython>=0.29 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (0.29.21)\n",
            "Collecting scipy<1.3,>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/d6/661cf4fb32ecda40fc03685ef0995db3d3300c619f461751621f646ab3f6/scipy-1.2.3-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8MB 63.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (1.1.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.6/dist-packages (from pmdarima==1.2.1) (0.22.2.post1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.9.0->pmdarima==1.2.1) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pmdarima==1.2.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->pmdarima==1.2.1) (2018.9)\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement scipy>=1.3.1, but you'll have scipy 1.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement scipy==1.4.1, but you'll have scipy 1.2.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, pmdarima\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed pmdarima-1.2.1 scipy-1.2.3\n",
            "Selecting previously unselected package libta-lib0.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack libta.deb ...\n",
            "Unpacking libta-lib0 (0.4.0-oneiric1) ...\n",
            "Selecting previously unselected package ta-lib0-dev.\n",
            "Preparing to unpack ta.deb ...\n",
            "Unpacking ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Setting up libta-lib0 (0.4.0-oneiric1) ...\n",
            "Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Collecting TA-Lib==0.4.17\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/05/d4c6a778d7a7de0be366bc4a850b4ffaeac2abad927f95fa8ba6f355a082/TA-Lib-0.4.17.tar.gz (717kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from TA-Lib==0.4.17) (1.18.5)\n",
            "Building wheels for collected packages: TA-Lib\n",
            "  Building wheel for TA-Lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TA-Lib: filename=TA_Lib-0.4.17-cp36-cp36m-linux_x86_64.whl size=2405533 sha256=be9f69250a2174e3d41761b438e92c52ee7465f5ad44c4f394364b64675ecf34\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/2e/ec/71c565b2e0091e03a2b56abfbfd062f14a01a8d7b20ffe8bd5\n",
            "Successfully built TA-Lib\n",
            "Installing collected packages: TA-Lib\n",
            "Successfully installed TA-Lib-0.4.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnJbyi0rnD7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0ceab2-66cc-43be-8d52-d545e56a9857"
      },
      "source": [
        "#mounting for using dataset and saving work\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEbae9cUlcHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a4c8973-530b-462e-efbb-8fb688436dc0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import kurtosis\n",
        "from pmdarima import auto_arima\n",
        "import pmdarima as pm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "import talib \n",
        "import json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiAP4uwSmSVg"
      },
      "source": [
        " #percentile difference between actual and predicted\n",
        "def mean_absolute_percentage_error(actual, prediction):\n",
        "    actual = pd.Series(actual)\n",
        "    prediction = pd.Series(prediction)\n",
        "    #mathematical calculation\n",
        "    return 100 * np.mean(np.abs((actual - prediction))/actual)\n",
        "\n",
        "  #ARIMA application\n",
        "def get_arima(data, train_len, test_len):\n",
        "    # prepare train and test data\n",
        "    data = data.tail(test_len + train_len).reset_index(drop=True)\n",
        "    train = data.head(train_len).values.tolist()\n",
        "    test = data.tail(test_len).values.tolist()\n",
        "\n",
        "    # Initialize model\n",
        "    #max_p is the max value of AR and max_q is the max value of MA\n",
        "    #train training data\n",
        "    model = auto_arima(train, max_p=3, max_q=3, seasonal=False, trace=True,\n",
        "                       error_action='ignore', suppress_warnings=True)\n",
        "\n",
        "    # Determine model parameters\n",
        "    #fitting model by exact maximum likelihood\n",
        "    model.fit(train)\n",
        "    order = model.get_params()['order']\n",
        "    print('ARIMA order:', order, '\\n')\n",
        "\n",
        "    # Genereate predictions\n",
        "    prediction = []\n",
        "    for i in range(len(test)):\n",
        "        #testing ARIMA\n",
        "        model = pm.ARIMA(order=order)\n",
        "        model.fit(train)\n",
        "        #printing the percentage of data completed while testing\n",
        "        print('working on', i+1, 'of', test_len, '-- ' + str(int(100 * (i + 1) / test_len)) + '% complete')\n",
        "        prediction.append(model.predict()[0])\n",
        "        train.append(test[i])\n",
        "\n",
        "    # Generate error data\n",
        "      #mean squared error\n",
        "    mse = mean_squared_error(test, prediction)\n",
        "      #root mean square error\n",
        "    rmse = mse ** 0.5\n",
        "      #mean absolute percentage error\n",
        "    mape = mean_absolute_percentage_error(pd.Series(test), pd.Series(prediction))\n",
        "    return prediction, mse, rmse, mape\n",
        "\n",
        "#\n",
        "def get_lstm(data, train_len, test_len, lstm_len=4):\n",
        "    # prepare train and test data\n",
        "    data = data.tail(test_len + train_len).reset_index(drop=True)\n",
        "      #reshaping the high volatality dataset \n",
        "    dataset = np.reshape(data.values, (len(data), 1))\n",
        "      #transform features by scaling each feature to the given range\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "      #fitting model by maximum likelihood\n",
        "    dataset_scaled = scaler.fit_transform(dataset)\n",
        "      #empty list for input and output of train and test\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    x_test = []\n",
        "      #splitting up the train and test dataset and reshaping it\n",
        "    for i in range(lstm_len, train_len):\n",
        "        x_train.append(dataset_scaled[i - lstm_len:i, 0])\n",
        "        y_train.append(dataset_scaled[i, 0])\n",
        "    for i in range(train_len, len(dataset_scaled)):\n",
        "        x_test.append(dataset_scaled[i - lstm_len:i, 0])\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "    x_test = np.array(x_test)\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "    # Set up & fit LSTM RNN (3 layers)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=lstm_len, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(LSTM(units=int(lstm_len/2)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    early_stopping = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
        "    model.fit(x_train, y_train, epochs=50, batch_size=1, verbose=2, callbacks=[early_stopping])\n",
        "\n",
        "    # Generate predictions\n",
        "    prediction = model.predict(x_test)\n",
        "    prediction = scaler.inverse_transform(prediction).tolist()\n",
        "      #storing predictions\n",
        "    output = []\n",
        "    for i in range(len(prediction)):\n",
        "        output.extend(prediction[i])\n",
        "    prediction = output\n",
        "\n",
        "    # Generate error data\n",
        "      #mean squared error\n",
        "    mse = mean_squared_error(data.tail(len(prediction)).values, prediction)\n",
        "      #root mean square error\n",
        "    rmse = mse ** 0.5\n",
        "      #mean absolute percentage error\n",
        "    mape = mean_absolute_percentage_error(data.tail(len(prediction)).reset_index(drop=True), pd.Series(prediction))\n",
        "    return prediction, mse, rmse, mape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JflafDkpmX_A"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "      # Loading data\n",
        "    path = 'drive/My Drive/data/'+'BA'+'_2006-01-01_to_2020-09-30.csv'\n",
        "    data1 = pd.read_csv(path,header=None)\n",
        "      # changing column order to: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume','Adj Close']\n",
        "    new_col=[0,3,1,2,4,5,6,7]\n",
        "      #assigning changed order \n",
        "    set(data1.columns) == set(new_col)\n",
        "    data=data1[new_col]\n",
        "      #dropping headers of the columns with names(str)\n",
        "    data = data.drop([0], axis=0)\n",
        "      #Initialize moving averages from Ta-Lib, store functions in dictionary\n",
        "    talib_moving_averages = ['SMA', 'EMA', 'WMA', 'DEMA', 'KAMA', 'MIDPOINT', 'T3', 'TEMA', 'TRIMA']\n",
        "\n",
        "    l=len(talib_moving_averages)\n",
        "      # Determine kurtosis \"K\" values for MA period 4-99\n",
        "    kurtosis_results = {'period': []} #dictionary to determine time period for MA\n",
        "    for i in range(4,100):\n",
        "        kurtosis_results['period'].append(i)\n",
        "        for ma in range(l):\n",
        "            # Run moving average, removing last 252 days (used later for test data set), trimming MA result to last 60 days\n",
        "            if ma == 0:\n",
        "              ma_output = talib.SMA(data.iloc[1006:3712,4],i).tail(60) #inbuilt function of TA-Lib syntax: talib._MA(data,timeperiod)\n",
        "            elif ma == 1:\n",
        "              ma_output = talib.EMA(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 2:\n",
        "              ma_output = talib.WMA(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 3:\n",
        "              ma_output = talib.DEMA(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 4:\n",
        "              ma_output = talib.KAMA(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 5:\n",
        "              ma_output = talib.MIDPOINT(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 6:\n",
        "              ma_output = talib.T3(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 7:\n",
        "              ma_output = talib.TEMA(data.iloc[1006:3712,4],i).tail(60)\n",
        "            elif ma == 8:\n",
        "              ma_output = talib.TRIMA(data.iloc[1006:3712,4],i).tail(60)\n",
        "\n",
        "            # Determine kurtosis \"K\" value\n",
        "            k = kurtosis(ma_output, fisher=False)\n",
        "    \n",
        "            # add to dictionary\n",
        "            if ma not in kurtosis_results.keys():\n",
        "                kurtosis_results[ma] = []\n",
        "            kurtosis_results[ma].append(k)\n",
        "\n",
        "    kurtosis_results = pd.DataFrame(kurtosis_results)\n",
        "    #print(kurtosis_results)\n",
        "\n",
        "    # Determine period with K closest to 3 +/- 5% (mesokurtic) \n",
        "    # Ordering the time period for the mesokurtic MA's in optimized_period\n",
        "    optimized_period = {}\n",
        "    for ma in range(l):\n",
        "        difference = np.abs(kurtosis_results[ma] - 3)\n",
        "        df = pd.DataFrame({'difference': difference, 'period': kurtosis_results['period']})\n",
        "        df = df.sort_values(by=['difference'], ascending=True).reset_index(drop=True)\n",
        "\n",
        "         # ordering and considering only mesokurtic time periods from kurtosis_results\n",
        "        if df.at[0, 'difference'] < 3 * 0.05:\n",
        "            optimized_period[ma] = df.at[0, 'period']\n",
        "        else:\n",
        "            print(str(ma) + ' is not viable, best K greater or less than 3 +/- 5%')\n",
        "\n",
        "    print('\\nOptimized periods:', optimized_period)\n",
        "\n",
        "    simulation = {}\n",
        "    for ma in optimized_period:\n",
        "        # Split data into low volatility and high volatility time series for ARIMA and LSTM based on MA type\n",
        "        if ma == 0:\n",
        "          low_vol = talib.SMA(data[4],optimized_period[ma]) #inbuilt function of TA-Lib\n",
        "          high_vol = data[4] - low_vol                      #subtracting 'Close' attribute from low voltalie dataset\n",
        "        elif ma == 1:\n",
        "          low_vol = talib.EMA(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 2:\n",
        "          low_vol = talib.WMA(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 3:\n",
        "          low_vol = talib.DEMA(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 4:\n",
        "          low_vol = talib.KAMA(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 5:\n",
        "          low_vol = talib.MIDPOINT(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 6:\n",
        "          low_vol = talib.T3(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 7:\n",
        "          low_vol = talib.TEMA(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "        elif ma == 8:\n",
        "          low_vol = talib.TRIMA(data[4],optimized_period[ma])\n",
        "          high_vol = data[4] - low_vol\n",
        "\n",
        "        # Generate ARIMA and LSTM predictions\n",
        "        print('\\nWorking on ' + str(ma) + ' predictions')\n",
        "        #compatibility of MA in ARIMA for dataset by calling ARIMA \n",
        "        try:\n",
        "            low_vol_prediction, low_vol_mse, low_vol_rmse, low_vol_mape = get_arima(low_vol, 1000, 252)\n",
        "        except:\n",
        "            print('ARIMA error, skipping to next MA type')\n",
        "            continue\n",
        "        #calling LSTM with high volatility parameters\n",
        "        high_vol_prediction, high_vol_mse, high_vol_rmse, high_vol_mape = get_lstm(high_vol, 1000, 252)\n",
        "\n",
        "        #calculating mse,rmse and mape to differentiate predictions and original\n",
        "        final_prediction = pd.Series(low_vol_prediction) + pd.Series(high_vol_prediction)\n",
        "        mse = mean_squared_error(final_prediction.values, data[4].tail(252).values)\n",
        "        rmse = mse ** 0.5\n",
        "        mape = mean_absolute_percentage_error(data[4].tail(252).reset_index(drop=True), final_prediction)\n",
        "\n",
        "        # Generate prediction accuracy\n",
        "        actual = data[4].tail(252).values\n",
        "        result_1 = []\n",
        "        result_2 = []\n",
        "        for i in range(1, len(final_prediction)):\n",
        "            # Compare prediction to previous close price\n",
        "            if final_prediction[i] > actual[i-1] and actual[i] > actual[i-1]:\n",
        "                result_1.append(1)\n",
        "            elif final_prediction[i] < actual[i-1] and actual[i] < actual[i-1]:\n",
        "                result_1.append(1)\n",
        "            else:\n",
        "                result_1.append(0)\n",
        "\n",
        "            # Compare prediction to previous prediction\n",
        "            if final_prediction[i] > final_prediction[i-1] and actual[i] > actual[i-1]:\n",
        "                result_2.append(1)\n",
        "            elif final_prediction[i] < final_prediction[i-1] and actual[i] < actual[i-1]:\n",
        "                result_2.append(1)\n",
        "            else:\n",
        "                result_2.append(0)\n",
        "\n",
        "        accuracy_1 = np.mean(result_1)\n",
        "        accuracy_2 = np.mean(result_2)\n",
        "          #storing predicted and the actual value\n",
        "        simulation[ma] = {'low_vol': {'prediction': low_vol_prediction, 'mse': low_vol_mse,\n",
        "                                      'rmse': low_vol_rmse, 'mape': low_vol_mape},\n",
        "                          'high_vol': {'prediction': high_vol_prediction, 'mse': high_vol_mse,\n",
        "                                       'rmse': high_vol_rmse},\n",
        "                          'final': {'prediction': final_prediction.values.tolist(), 'mse': mse,\n",
        "                                    'rmse': rmse, 'mape': mape},\n",
        "                          'accuracy': {'prediction vs close': accuracy_1, 'prediction vs prediction': accuracy_2}}\n",
        "\n",
        "        # save simulation data here as checkpoint\n",
        "        with open('drive/My Drive/data/results/simulation_data.json', 'w') as fp:\n",
        "            json.dump(simulation, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpeP28Di76aI",
        "outputId": "2fa68d61-1412-4bf0-bcea-96f7ce6b1197"
      },
      "source": [
        "#comparing prediction vs original dataset\n",
        "for ma in simulation.keys():\n",
        "        print('\\n' + str(ma))\n",
        "        print('Prediction vs Close:\\t\\t' + str(round(100*simulation[ma]['accuracy']['prediction vs close'], 2))\n",
        "              + '% Accuracy')\n",
        "        print('Prediction vs Prediction:\\t' + str(round(100*simulation[ma]['accuracy']['prediction vs prediction'], 2))\n",
        "              + '% Accuracy')\n",
        "        print('MSE:\\t', simulation[ma]['final']['mse'],\n",
        "              '\\nRMSE:\\t', simulation[ma]['final']['rmse'],\n",
        "              '\\nMAPE:\\t', simulation[ma]['final']['mape'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1\n",
            "Prediction vs Close:\t\t51.0% Accuracy\n",
            "Prediction vs Prediction:\t46.22% Accuracy\n",
            "MSE:\t 323.5499349640634 \n",
            "RMSE:\t 17.987493848895777 \n",
            "MAPE:\t 5.490833127018244\n",
            "\n",
            "2\n",
            "Prediction vs Close:\t\t52.99% Accuracy\n",
            "Prediction vs Prediction:\t47.81% Accuracy\n",
            "MSE:\t 659.8241498287745 \n",
            "RMSE:\t 25.687042450013088 \n",
            "MAPE:\t 8.411223935964577\n",
            "\n",
            "3\n",
            "Prediction vs Close:\t\t50.2% Accuracy\n",
            "Prediction vs Prediction:\t47.01% Accuracy\n",
            "MSE:\t 162.87786625652433 \n",
            "RMSE:\t 12.76236131194084 \n",
            "MAPE:\t 4.206384989658252\n",
            "\n",
            "4\n",
            "Prediction vs Close:\t\t50.6% Accuracy\n",
            "Prediction vs Prediction:\t46.61% Accuracy\n",
            "MSE:\t 316.95786750860594 \n",
            "RMSE:\t 17.803310577210237 \n",
            "MAPE:\t 5.238793308460417\n",
            "\n",
            "5\n",
            "Prediction vs Close:\t\t52.59% Accuracy\n",
            "Prediction vs Prediction:\t48.61% Accuracy\n",
            "MSE:\t 274.3950291643885 \n",
            "RMSE:\t 16.564873351897035 \n",
            "MAPE:\t 6.367435051312706\n",
            "\n",
            "8\n",
            "Prediction vs Close:\t\t45.82% Accuracy\n",
            "Prediction vs Prediction:\t46.61% Accuracy\n",
            "MSE:\t 987.4568844423396 \n",
            "RMSE:\t 31.4238266995339 \n",
            "MAPE:\t 10.651317134884952\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}